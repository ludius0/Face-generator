{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"face-generator.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNmwGrFeKvNH6uRoEdBVAH/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"bC068H0fqmIq","colab_type":"text"},"source":["**AUTHORIZATIONS**"]},{"cell_type":"code","metadata":{"id":"ZuGMXjF83_91","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('./mount')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jHshYc0_6_8F","colab_type":"text"},"source":["**IMPORT LIBRARIES**"]},{"cell_type":"code","metadata":{"id":"BoNe_YRZ0cAm","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596456770319,"user_tz":-120,"elapsed":5286,"user":{"displayName":"Tomáš Novotný","photoUrl":"","userId":"10641169689505851937"}}},"source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset\n","\n","import h5py\n","import random\n","from time import strftime, localtime\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import os\n","import sys\n","import zipfile\n","import imageio\n","from tqdm.notebook import tqdm"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zJT8zqtLj8Qt","colab_type":"text"},"source":["**CONVERT TO HDF5**"]},{"cell_type":"code","metadata":{"id":"XHda9mPN01eT","colab_type":"code","colab":{}},"source":["def convert_to_hdf5_file(index_):\n","\n","  hdf5_file = f\"mount/My Drive/Colab Notebooks/celebA/{index_}_img_align_celeba.h5py\"\n","\n","  # how many of the 202,599 images to extract and package into HDF5\n","  total_images = int(index_)\n","\n","  with h5py.File(hdf5_file, \"w\") as hf:\n","      count = 0\n","      with zipfile.ZipFile(\"mount/My Drive/Colab Notebooks/celebA/img_align_celeba.zip\", \"r\") as zf:\n","        for i in tqdm(zf.namelist(), total=index_):\n","          if i[-4:] == \".jpg\":\n","\n","            # extract image\n","            ofile = zf.extract(i)\n","            img = imageio.imread(ofile)\n","            os.remove(ofile)\n","\n","            # add image data to HDF5 file with new name\n","            hf.create_dataset(\"img_align_celeba/\"+str(count)+\".jpg\", data=img, compression=\"gzip\", compression_opts=9)\n","            \n","            count += 1\n","\n","            # stop when total_images reached\n","            if count == total_images:\n","              break\n","\n","convert_to_hdf5_file(20_096)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WilMBz7A665u","colab_type":"text"},"source":["**NETWORKS**"]},{"cell_type":"code","metadata":{"id":"d7Vh1KOW0e1c","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596456770322,"user_tz":-120,"elapsed":2850,"user":{"displayName":"Tomáš Novotný","photoUrl":"","userId":"10641169689505851937"}}},"source":["class CelebADataset(Dataset):\n","    \n","    def __init__(self, file):\n","      self.file_object = h5py.File(file, \"r\")\n","      self.dataset = self.file_object[\"img_align_celeba\"]\n","    \n","    def __len__(self):\n","      return len(self.dataset)\n","    \n","    def __getitem__(self, index):\n","      if (index >= len(self.dataset)):\n","        raise IndexError()\n","      img = np.array(self.dataset[str(index)+\".jpg\"])\n","      img = self.crop_to_centre_img(img, 128, 128)\n","      return torch.cuda.FloatTensor(img).permute(2, 0, 1).view(1, 3, 128, 128) / 255.0\n","    \n","    def crop_to_centre_img(self, img, width, height):\n","      img_height, img_width, _ = img.shape\n","      x = img_width // 2 - width // 2\n","      y = img_height // 2 - height // 2\n","      return img[y: y + height, x: x + width, :]\n","    \n","    def plot_image(self, index):\n","      img = np.array(self.dataset[str(index)+'.jpg'])\n","      img = self.crop_to_centre_img(img, 128, 128)\n","      plt.imshow(img, interpolation='nearest')\n","\n","class View(nn.Module):\n","    def __init__(self, shape):\n","      super().__init__()\n","      \"\"\"\n","      Reshape 3-dimensional Tensor to 1-Dimensional Tensor (Vector) or vice versa\n","      \"\"\"\n","      self.shape = shape,\n","\n","    def forward(self, x):\n","      return x.reshape(*self.shape)\n","\n","class Discriminator(nn.Module):\n","    def __init__(self):\n","      super().__init__()\n","      \"\"\"\n","      Create structure of NN\n","      \"\"\"\n","      \n","      # Neural Network layers\n","      self.model = nn.Sequential(\n","            View((1, 3, 128, 128)),\n","\n","            nn.Conv2d(3, 256, kernel_size=8, stride=2),\n","            nn.BatchNorm2d(256),\n","            nn.GELU(),\n","            \n","            nn.Conv2d(256, 256, kernel_size=8, stride=2),\n","            nn.BatchNorm2d(256),\n","            nn.GELU(),\n","            \n","            nn.Conv2d(256, 3, kernel_size=8, stride=2),\n","            nn.GELU(),\n","            \n","            View(3*10*10),\n","            nn.Linear(3*10*10, 1),\n","            nn.Sigmoid()\n","          )\n","\n","      # Mean square loss\n","      self.loss_function = nn.MSELoss()\n","\n","      # Adam optimiser\n","      self.optimiser = torch.optim.Adam(self.parameters(), lr=0.0001)\n","\n","      # Timestap of loss for ploting progress\n","      self.counter = 0\n","      self.progress = []\n","    \n","    \n","    def forward(self, inputs):\n","      \"\"\"\n","      Pass through NN and get its answer\n","      \"\"\"\n","      return self.model(inputs)\n","    \n","    \n","    def train(self, inputs, targets):\n","      \"\"\"\n","      Train NN; Take tensor of image with label identificator of image;\n","      Pass through NN; get loss/cost function and backpropagate NN\n","      to tweak weights (layers)\n","      \"\"\"\n","      outputs = self.forward(inputs)\n","      loss = self.loss_function(outputs, targets)\n","\n","      # For timestamp and plotting\n","      self.counter += 1\n","      if (self.counter % 10000 == 0):\n","          self.progress.append(loss.item())\n","\n","      # Backpropagation -> zero gradients, perform a backward pass, update weights\n","      self.optimiser.zero_grad()\n","      loss.backward()\n","      self.optimiser.step()\n","    \n","    \n","    def plot_progress(self):\n","      \"\"\"\n","      Plot loss of NN for every image it was trained\n","      \"\"\"\n","      df = pd.DataFrame(self.progress, columns=['loss'])\n","      df.plot(ylim=(0), figsize=(16,8), alpha=0.1, marker='.', grid=True,\n","                yticks=(0, 0.25, 0.5, 1.0, 5.0), title=\"Discriminator Loss\")\n","\n","class Generator(nn.Module):\n","    \n","    def __init__(self):\n","      super().__init__()\n","      \"\"\"\n","      Create structure of NN\n","      \"\"\"\n","      self.model = nn.Sequential(\n","            # reshape to z (_, z, y, x)\n","            nn.Linear(100, 3*11*11),\n","            nn.GELU(),\n","            View((1, 3, 11, 11)),\n","            \n","            nn.ConvTranspose2d(3, 256, kernel_size=8, stride=2),\n","            nn.BatchNorm2d(256),\n","            nn.GELU(),\n","\n","            nn.ConvTranspose2d(256, 256, kernel_size=8, stride=2),\n","            nn.BatchNorm2d(256),\n","            nn.GELU(),\n","\n","            nn.ConvTranspose2d(256, 3, kernel_size=8, stride=2, padding=1),\n","            nn.BatchNorm2d(3),\n","            \n","            # output is (1,3,128,128)\n","            nn.Sigmoid()\n","          )\n","\n","      # No loss function; will use one from discriminator to calculate error\n","\n","      self.optimiser = torch.optim.Adam(self.parameters(), lr=0.0001)\n","\n","      # counter and accumulator for progress\n","      self.counter = 0\n","      self.progress = []\n","\n","    def forward(self, inputs):        \n","      \"\"\"\n","      Pass through NN and get its answer\n","      \"\"\"\n","      return self.model(inputs)\n","    \n","    \n","    def train(self, D, inputs, targets):\n","      \"\"\"\n","      Train NN; Take tensor of image with label identificator of image;\n","      Pass through NN; get loss/cost function and backpropagate NN\n","      to tweak weights (layers)\n","      \"\"\"\n","      g_output = self.forward(inputs)\n","      d_output = D.forward(g_output)\n","      \n","      loss = D.loss_function(d_output, targets)\n","\n","      self.counter += 1\n","      if (self.counter % 10000 == 0):\n","          self.progress.append(loss.item())\n","\n","      # Backpropagation\n","      self.optimiser.zero_grad()\n","      loss.backward()\n","      self.optimiser.step()\n","    \n","    def plot_progress(self):\n","      \"\"\"\n","      Plot loss of NN for every image it was trained\n","      \"\"\"\n","      df = pd.DataFrame(self.progress, columns=['loss'])\n","      df.plot(ylim=(0), figsize=(16,8), alpha=0.1, marker='.', grid=True,\n","              yticks=(0, 0.25, 0.5, 1.0, 5.0), title=\"Generator Loss\")"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TLI3sCr361N_","colab_type":"text"},"source":["**FUNCTIONS**"]},{"cell_type":"code","metadata":{"id":"GI3LSvNt0h4S","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596456774223,"user_tz":-120,"elapsed":2554,"user":{"displayName":"Tomáš Novotný","photoUrl":"","userId":"10641169689505851937"}}},"source":["# functions to generate random data\n","def generate_random_image(size):\n","    random_data = torch.rand(size)\n","    return random_data\n","\n","def generate_random_seed(size):\n","    random_data = torch.randn(size)\n","    return random_data\n","\n","# Functions to plot\n","def plot_loss():\n","    D.plot_progress()\n","    G.plot_progress()\n","\n","def save_plot(G, epoch):\n","    fig, ax = plt.subplots(figsize=(16, 8))\n","    output = G.forward(generate_random_seed(100))\n","    img = output.detach().permute(0, 2, 3, 1).reshape(128, 128, 3).cpu().numpy()\n","    ax.imshow(img, interpolation=\"none\", cmap=\"Blues\")\n","    timestamp = strftime(\"%Y-%m-%d %H-%M-%S\", localtime())\n","    plt.savefig(f\"mount/My Drive/Colab Notebooks/celebA/generated images/single_face_{timestamp}.png\")\n","\n","def plot_results(G, seed1, seed2, epoch=None, save_img=False):\n","    # Plot 6 images\n","    rows, columns = 2, 3\n","    fig, ax = plt.subplots(rows, columns, figsize=(16, 8))\n","    for i in range(rows):\n","        for j in range(columns):\n","            if i == rows-1 and j == columns:        # Last in penultimate row is seed1-seed2\n","                output = G.forward(seed1-seed2)\n","            elif i == rows and j == columns:        # Last in last row is seed1+seed2\n","                output = G.forward(seed1+seed2)\n","            elif i == rows-1 and j == columns-1:    # Penultimate in penultimate row is seed1\n","                output = G.forward(seed1)\n","            elif i == rows and j == columns-1:      # Penultimate in last row is seed2\n","                output = G.forward(seed2)\n","            else:                                   # Everything else is random\n","                output = G.forward(generate_random_seed(100))\n","            img = output.detach().permute(0, 2, 3, 1).view(128, 128, 3).cpu().numpy()\n","            ax[i,j].imshow(img, interpolation=\"none\", cmap=\"Blues\")\n","\n","    if save_img == True:\n","      timestamp = strftime(\"%Y-%m-%d %H-%M-%S\", localtime())\n","      plt.savefig(f\"mount/My Drive/Colab Notebooks/celebA/generated images/epoch_{epoch}_{timestamp}.png\")\n","  \n","# Save\n","def save_model(G, D, state_dict=True):\n","    if state_dict == True:\n","      PATH = \"mount/My Drive/Colab Notebooks/celebA/models/generator.pt\"\n","      torch.save(G.state_dict(), PATH)\n","      PATH = \"mount/My Drive/Colab Notebooks/celebA/models/discriminator.pt\"\n","      torch.save(D.state_dict(), PATH)\n","    else:\n","      PATH = \"mount/My Drive/Colab Notebooks/celebA/models/generator.pt\"\n","      torch.save(G, PATH)\n","      PATH = \"mount/My Drive/Colab Notebooks/celebA/models/discriminator.pt\"\n","      torch.save(D, PATH)"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"seYdiAQwcQYh","colab_type":"text"},"source":["**CUDA**"]},{"cell_type":"code","metadata":{"id":"OEiuqf2TcM_0","colab_type":"code","colab":{}},"source":["# CUDA\n","if torch.cuda.is_available():\n","  torch.set_default_tensor_type(torch.cuda.FloatTensor)\n","  print(\"using cuda:\", torch.cuda.get_device_name(0))\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xLGS1GEVl3-0","colab_type":"text"},"source":["**PREPARE NETWORKS**"]},{"cell_type":"code","metadata":{"id":"tZ7deaIrlsgS","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596456794051,"user_tz":-120,"elapsed":13099,"user":{"displayName":"Tomáš Novotný","photoUrl":"","userId":"10641169689505851937"}}},"source":["dataset = CelebADataset(\"mount/My Drive/Colab Notebooks/celebA/20096_img_align_celeba.h5py\")\n","D = Discriminator().to(device)\n","G = Generator().to(device)\n","\n","seed1 = generate_random_seed(100)\n","seed2 = generate_random_seed(100)"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tdoFD8g-l-0U","colab_type":"text"},"source":["**LOAD NETWORKS** (In case of disconnection in training)"]},{"cell_type":"code","metadata":{"id":"Zo2CYqzjlr0u","colab_type":"code","colab":{}},"source":["PATH = \"mount/My Drive/Colab Notebooks/celebA/models/discriminator.pt\"\n","D.load_state_dict(torch.load(PATH))\n","PATH = \"mount/My Drive/Colab Notebooks/celebA/models/generator.pt\"\n","G.load_state_dict(torch.load(PATH))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tG6L2XMWmVUM","colab_type":"text"},"source":["**TEST NETWOKS OUTPUT SHAPE**"]},{"cell_type":"code","metadata":{"id":"OUUM43simULQ","colab_type":"code","colab":{}},"source":["for index, img_tensor in enumerate(dataset):\n","  print(img_tensor.shape)\n","  d_output = D.forward(img_tensor)\n","  print(d_output.shape)\n","  g_output = G.forward(generate_random_seed(100))\n","  print(g_output.shape)\n","  break"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V1F2Wv5brXCr","colab_type":"text"},"source":["**TRAIN**"]},{"cell_type":"code","metadata":{"id":"9VFMj3BwxaaO","colab_type":"code","colab":{}},"source":["# Train\n","epochs = 20\n","for e in range(epochs):\n","    print(f\"\\nTraining in {e+1} / {epochs} epochs...\")\n","    for index, img_tensor in tqdm(enumerate(dataset), total=len(dataset)): # <- slow code\n","    # for index, img_tensor in enumerate(dataset):\n","      # Train Discriminator -> Real data\n","      D.train(img_tensor, torch.cuda.FloatTensor([1.0]))\n","\n","      # Train Discriminator -> Fake data\n","      D.train(G.forward(generate_random_seed(100)).detach(), torch.cuda.FloatTensor([0.0]))\n","\n","      # Train Generator\n","      G.train(D, generate_random_seed(100), torch.cuda.FloatTensor([1.0]))\n","\n","    # Save models\n","    save_model(G, D)\n","    \n","    # Save progress and plot\n","    save_plot(G, e)\n","    plot_results(G, seed1, seed2, save_img=True)\n","\n","# PLOT\n","plot_loss()\n","plot_results(G, seed1, seed2, save_img=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PayChvqyxNLZ","colab_type":"text"},"source":["**MEMORY**"]},{"cell_type":"code","metadata":{"id":"W9AV8pFnxB5f","colab_type":"code","colab":{}},"source":["print(torch.cuda.memory_summary(device, abbreviated=True))"],"execution_count":null,"outputs":[]}]}